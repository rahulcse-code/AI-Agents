{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulcse-code/Rakshak-/blob/main/North_East_Weather_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "import webbrowser\n",
        "\n",
        "# ==========================================\n",
        "# CONFIGURATION & SETUP\n",
        "# ==========================================\n",
        "# We define real coordinates for North East Capitals\n",
        "NE_CITIES = {\n",
        "    \"1\": {\"name\": \"Gangtok, Sikkim\", \"lat\": 27.3314, \"lon\": 88.6138, \"wiki\": \"Gangtok\"},\n",
        "    \"2\": {\"name\": \"Shillong, Meghalaya\", \"lat\": 25.5788, \"lon\": 91.8933, \"wiki\": \"Shillong\"},\n",
        "    \"3\": {\"name\": \"Guwahati, Assam\", \"lat\": 26.1445, \"lon\": 91.7362, \"wiki\": \"Guwahati\"},\n",
        "    \"4\": {\"name\": \"Kohima, Nagaland\", \"lat\": 25.6701, \"lon\": 94.1077, \"wiki\": \"Kohima\"},\n",
        "    \"5\": {\"name\": \"Aizawl, Mizoram\", \"lat\": 23.7271, \"lon\": 92.7176, \"wiki\": \"Aizawl\"},\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# SOURCE 1: REAL-TIME WEATHER API (Open-Meteo)\n",
        "# ==========================================\n",
        "def fetch_live_weather(lat, lon):\n",
        "    \"\"\"\n",
        "    Connects to Open-Meteo Satellite API to get live weather metrics.\n",
        "    \"\"\"\n",
        "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"current_weather\": \"true\",\n",
        "        \"hourly\": \"temperature_2m,relativehumidity_2m,precipitation\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status() # Raise error if website is down\n",
        "        data = response.json()\n",
        "\n",
        "        current = data['current_weather']\n",
        "        return {\n",
        "            \"temp\": current['temperature'],\n",
        "            \"wind\": current['windspeed'],\n",
        "            \"code\": current['weathercode'] # WMO Weather interpretation codes\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå CRITICAL ERROR: Could not connect to Weather Satellite. {e}\")\n",
        "        exit() # STOP execution. No fake data allowed.\n",
        "\n",
        "# ==========================================\n",
        "# SOURCE 2: LIVE WEB SCRAPING (Wikipedia)\n",
        "# ==========================================\n",
        "def scrape_city_description(wiki_suffix):\n",
        "    \"\"\"\n",
        "    Scrapes the first paragraph of the city's Wikipedia page.\n",
        "    \"\"\"\n",
        "    url = f\"https://en.wikipedia.org/wiki/{wiki_suffix}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Wikipedia content is usually in <p> tags under mw-parser-output\n",
        "        # We grab the first meaningful paragraph\n",
        "        paragraphs = soup.find_all('p')\n",
        "        for p in paragraphs:\n",
        "            text = p.get_text().strip()\n",
        "            if len(text) > 50: # Skip empty or short header paragraphs\n",
        "                return text[:300] + \"...\" # Return first 300 chars\n",
        "\n",
        "        return \"Description not found on Wikipedia.\"\n",
        "    except Exception as e:\n",
        "        return f\"Could not scrape Wikipedia: {e}\"\n",
        "\n",
        "# ==========================================\n",
        "# COMPONENT 3: MACHINE LEARNING ENGINE\n",
        "# ==========================================\n",
        "def train_activity_predictor():\n",
        "    \"\"\"\n",
        "    Trains a Random Forest Classifier on a synthetic expert knowledge base.\n",
        "    Features: [Temperature, WindSpeed, WeatherCode]\n",
        "    Target: Activity Class\n",
        "    \"\"\"\n",
        "    # Creating a \"Synthetic Historical Dataset\" representing 1000 days of expert decisions\n",
        "    # This simulates having a CSV of past user preferences.\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for _ in range(1000):\n",
        "        # Simulate varied weather conditions\n",
        "        t = random.uniform(0, 35) # Temp range 0-35C\n",
        "        w = random.uniform(0, 25) # Wind range\n",
        "        c = random.choice([0, 1, 2, 3, 51, 61, 80, 95]) # WMO codes (Clear to Storm)\n",
        "\n",
        "        # EXPERT LOGIC for Ground Truth Labels\n",
        "        if c >= 80: label = \"Stay Indoors\" # Storm/Rain\n",
        "        elif c >= 51: label = \"Cafe/Museum\" # Drizzle\n",
        "        elif t > 30: label = \"Water Park/Pool\" # Hot\n",
        "        elif t < 10 and w > 10: label = \"Cafe/Museum\" # Cold & Windy\n",
        "        elif t < 10: label = \"Bonfire/Hot Spring\" # Cold but calm\n",
        "        elif t > 15 and c < 3: label = \"Trekking/Nature\" # Pleasant\n",
        "        else: label = \"City Walk\"\n",
        "\n",
        "        X_train.append([t, w, c])\n",
        "        y_train.append(label)\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "# ==========================================\n",
        "# COMPONENT 4: AGENTIC AI (MAIN SYSTEM)\n",
        "# ==========================================\n",
        "def run_smart_agent():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"   ECO-SMART NORTH EAST TOURISM AGENT (V2.0)\")\n",
        "    print(\"   Capabilities: Live Weather API + Wikipedia Scraping + ML Analysis\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. User Selection\n",
        "    print(\"\\nSelect Area of Interest:\")\n",
        "    for k, v in NE_CITIES.items():\n",
        "        print(f\"  {k}. {v['name']}\")\n",
        "\n",
        "    choice = input(\"\\nEnter Choice (1-5): \")\n",
        "    city_data = NE_CITIES.get(choice)\n",
        "\n",
        "    if not city_data:\n",
        "        print(\"‚ùå Invalid Selection.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüîÑ AGENT STATUS: Connecting to Satellite & Wikipedia for {city_data['name']}...\")\n",
        "\n",
        "    # 2. Parallel Data Collection (API + Scraping)\n",
        "    weather = fetch_live_weather(city_data['lat'], city_data['lon'])\n",
        "    description = scrape_city_description(city_data['wiki'])\n",
        "\n",
        "    print(\"‚úÖ Data Acquisition Complete.\")\n",
        "\n",
        "    # 3. ML Analysis\n",
        "    print(\"üß† Running Random Forest Classifier...\")\n",
        "    ml_model = train_activity_predictor()\n",
        "\n",
        "    # Predict based on live data\n",
        "    prediction = ml_model.predict([[weather['temp'], weather['wind'], weather['code']]])[0]\n",
        "\n",
        "    # 4. Generate Report\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(f\"üìÑ INTELLIGENT REPORT: {city_data['name']}\")\n",
        "    print(\"-\"*50)\n",
        "    print(f\"üåç About Location: \\\"{description}\\\"\")\n",
        "    print(f\"\\nüå§Ô∏è  LIVE WEATHER CONDITIONS:\")\n",
        "    print(f\"    ‚Ä¢ Temperature: {weather['temp']}¬∞C\")\n",
        "    print(f\"    ‚Ä¢ Wind Speed:  {weather['wind']} km/h\")\n",
        "    print(f\"    ‚Ä¢ Condition Code: {weather['code']} (WMO Standard)\")\n",
        "    print(\"-\"*50)\n",
        "    print(f\"ü§ñ AI RECOMMENDATION: {prediction}\")\n",
        "    print(f\"   Reasoning: Based on {weather['temp']}¬∞C and current sky conditions.\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    # 5. Agent Action (Real-world interaction)\n",
        "    nav_q = input(\"üöÄ Open recommended locations on Google Maps? (y/n): \")\n",
        "    if nav_q.lower() == 'y':\n",
        "        query = f\"{prediction} in {city_data['name']}\"\n",
        "        url = f\"https://www.google.com/maps/search/{query}\"\n",
        "        webbrowser.open(url)\n",
        "        print(f\"‚úÖ Browser opened: {url}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_smart_agent()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "   ECO-SMART NORTH EAST TOURISM AGENT (V2.0)\n",
            "   Capabilities: Live Weather API + Wikipedia Scraping + ML Analysis\n",
            "==================================================\n",
            "\n",
            "Select Area of Interest:\n",
            "  1. Gangtok, Sikkim\n",
            "  2. Shillong, Meghalaya\n",
            "  3. Guwahati, Assam\n",
            "  4. Kohima, Nagaland\n",
            "  5. Aizawl, Mizoram\n",
            "\n",
            "Enter Choice (1-5): 3\n",
            "\n",
            "üîÑ AGENT STATUS: Connecting to Satellite & Wikipedia for Guwahati, Assam...\n",
            "‚úÖ Data Acquisition Complete.\n",
            "üß† Running Random Forest Classifier...\n",
            "\n",
            "--------------------------------------------------\n",
            "üìÑ INTELLIGENT REPORT: Guwahati, Assam\n",
            "--------------------------------------------------\n",
            "üåç About Location: \"Description not found on Wikipedia.\"\n",
            "\n",
            "üå§Ô∏è  LIVE WEATHER CONDITIONS:\n",
            "    ‚Ä¢ Temperature: 23.8¬∞C\n",
            "    ‚Ä¢ Wind Speed:  2.8 km/h\n",
            "    ‚Ä¢ Condition Code: 1 (WMO Standard)\n",
            "--------------------------------------------------\n",
            "ü§ñ AI RECOMMENDATION: Trekking/Nature\n",
            "   Reasoning: Based on 23.8¬∞C and current sky conditions.\n",
            "--------------------------------------------------\n",
            "üöÄ Open recommended locations on Google Maps? (y/n): y\n",
            "‚úÖ Browser opened: https://www.google.com/maps/search/Trekking/Nature in Guwahati, Assam\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsNzLl3QOPpU",
        "outputId": "24c37b26-2168-45f3-8cd1-83ebc5c03e6f"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}